{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_Fast_API",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnHdxZBfEvvM",
        "outputId": "01e03634-f0c9-4316-b9c9-e62ae8745236"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive')\n",
        "%cd drive/MyDrive/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mqtscUdExm8",
        "outputId": "145c1148-3ee5-42f4-9b7e-1b99d6d55980"
      },
      "source": [
        "!pip install uvicorn\n",
        "!pip install fastapi\n",
        "!pip install nest_asyncio\n",
        "!pip install pystan\n",
        "!pip install prophet\n",
        "!pip install pyngrok \n",
        "!pip install pmdarima\n",
        "!pip install -v scikit-learn==0.23.2"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.7/dist-packages (0.14.0)\n",
            "Requirement already satisfied: asgiref>=3.3.4 in /usr/local/lib/python3.7/dist-packages (from uvicorn) (3.4.0)\n",
            "Requirement already satisfied: click>=7.* in /usr/local/lib/python3.7/dist-packages (from uvicorn) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from uvicorn) (3.7.4.3)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.7/dist-packages (from uvicorn) (0.12.0)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.7/dist-packages (0.65.2)\n",
            "Requirement already satisfied: pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2 in /usr/local/lib/python3.7/dist-packages (from fastapi) (1.8.2)\n",
            "Requirement already satisfied: starlette==0.14.2 in /usr/local/lib/python3.7/dist-packages (from fastapi) (0.14.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2->fastapi) (3.7.4.3)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.7/dist-packages (1.5.1)\n",
            "Requirement already satisfied: pystan in /usr/local/lib/python3.7/dist-packages (2.19.1.1)\n",
            "Requirement already satisfied: Cython!=0.25.1,>=0.22 in /usr/local/lib/python3.7/dist-packages (from pystan) (0.29.23)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from pystan) (1.19.5)\n",
            "Requirement already satisfied: prophet in /usr/local/lib/python3.7/dist-packages (1.0.1)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from prophet) (3.2.2)\n",
            "Requirement already satisfied: tqdm>=4.36.1 in /usr/local/lib/python3.7/dist-packages (from prophet) (4.41.1)\n",
            "Requirement already satisfied: cmdstanpy==0.9.68 in /usr/local/lib/python3.7/dist-packages (from prophet) (0.9.68)\n",
            "Requirement already satisfied: pystan~=2.19.1.1 in /usr/local/lib/python3.7/dist-packages (from prophet) (2.19.1.1)\n",
            "Requirement already satisfied: LunarCalendar>=0.0.9 in /usr/local/lib/python3.7/dist-packages (from prophet) (0.0.9)\n",
            "Requirement already satisfied: setuptools-git>=1.2 in /usr/local/lib/python3.7/dist-packages (from prophet) (1.2)\n",
            "Requirement already satisfied: convertdate>=2.1.2 in /usr/local/lib/python3.7/dist-packages (from prophet) (2.3.2)\n",
            "Requirement already satisfied: pandas>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from prophet) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from prophet) (1.19.5)\n",
            "Requirement already satisfied: holidays>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from prophet) (0.10.5.2)\n",
            "Requirement already satisfied: Cython>=0.22 in /usr/local/lib/python3.7/dist-packages (from prophet) (0.29.23)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from prophet) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->prophet) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->prophet) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->prophet) (2.4.7)\n",
            "Requirement already satisfied: ujson in /usr/local/lib/python3.7/dist-packages (from cmdstanpy==0.9.68->prophet) (4.0.2)\n",
            "Requirement already satisfied: ephem>=3.7.5.3 in /usr/local/lib/python3.7/dist-packages (from LunarCalendar>=0.0.9->prophet) (4.0.0.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from LunarCalendar>=0.0.9->prophet) (2018.9)\n",
            "Requirement already satisfied: pymeeus<=1,>=0.3.13 in /usr/local/lib/python3.7/dist-packages (from convertdate>=2.1.2->prophet) (0.5.11)\n",
            "Requirement already satisfied: korean-lunar-calendar in /usr/local/lib/python3.7/dist-packages (from holidays>=0.10.2->prophet) (0.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from holidays>=0.10.2->prophet) (1.15.0)\n",
            "Requirement already satisfied: hijri-converter in /usr/local/lib/python3.7/dist-packages (from holidays>=0.10.2->prophet) (2.1.2)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.7/dist-packages (5.0.5)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyngrok) (3.13)\n",
            "Requirement already satisfied: pmdarima in /usr/local/lib/python3.7/dist-packages (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.7/dist-packages (from pmdarima) (1.4.1)\n",
            "Requirement already satisfied: statsmodels!=0.12.0,>=0.11 in /usr/local/lib/python3.7/dist-packages (from pmdarima) (0.12.2)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.7/dist-packages (from pmdarima) (0.23.2)\n",
            "Requirement already satisfied: Cython!=0.29.18,>=0.29 in /usr/local/lib/python3.7/dist-packages (from pmdarima) (0.29.23)\n",
            "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.7/dist-packages (from pmdarima) (1.1.5)\n",
            "Requirement already satisfied: numpy~=1.19.0 in /usr/local/lib/python3.7/dist-packages (from pmdarima) (1.19.5)\n",
            "Requirement already satisfied: setuptools!=50.0.0,>=38.6.0 in /usr/local/lib/python3.7/dist-packages (from pmdarima) (57.0.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from pmdarima) (1.24.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from pmdarima) (1.0.1)\n",
            "Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.7/dist-packages (from statsmodels!=0.12.0,>=0.11->pmdarima) (0.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22->pmdarima) (2.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.19->pmdarima) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.19->pmdarima) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from patsy>=0.5->statsmodels!=0.12.0,>=0.11->pmdarima) (1.15.0)\n",
            "Created temporary directory: /tmp/pip-ephem-wheel-cache-qlfm22tq\n",
            "Created temporary directory: /tmp/pip-req-tracker-p72c1qxz\n",
            "Created requirements tracker '/tmp/pip-req-tracker-p72c1qxz'\n",
            "Created temporary directory: /tmp/pip-install-r1jwi6ue\n",
            "Requirement already satisfied: scikit-learn==0.23.2 in /usr/local/lib/python3.7/dist-packages (0.23.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.2) (1.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.2) (2.1.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.2) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.2) (1.4.1)\n",
            "Cleaning up...\n",
            "Removed build tracker '/tmp/pip-req-tracker-p72c1qxz'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RHRMUHcFMzL"
      },
      "source": [
        "# for FastAPI\n",
        "from fastapi import FastAPI\n",
        "import uvicorn\n",
        "import pydantic\n",
        "from pyngrok import ngrok\n",
        "import nest_asyncio\n",
        "# for FBprophet\n",
        "from datetime import *\n",
        "import pandas_datareader as pdr\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import holidays\n",
        "from prophet import Prophet\n",
        "# for arima\n",
        "from statsmodels.tsa.arima_model import ARIMA\n",
        "import pmdarima as pm\n",
        "# for LSTM\n",
        " \n",
        "from tensorflow.keras.models import load_model\n",
        "import pickle\n",
        "# for transformer\n",
        "from utils.Time2Vector import Time2Vector\n",
        "from utils.Attention import MultiAttention, SingleAttention\n",
        "from utils.Encoder import TransformerEncoder\n",
        "from tensorflow import keras\n",
        "import warnings\n",
        "nest_asyncio.apply()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4j5I4eI4QL1l"
      },
      "source": [
        "def indicator(reg_pred,arima_pred,lstm_pred,prophet_pred,trans_pred,real):\n",
        "  '''\n",
        "    Take Decision based on specific formula \n",
        "    Args:\n",
        "        (float) Regression prediciton - the predcition of Ensemble Regression Models\n",
        "        (float) Arima prediciton - the predcition of Arima Model\n",
        "        (float) LSTM prediciton - the predcition of LSTM Model\n",
        "        (float) Prophet prediciton - the predcition of Prophet Model\n",
        "        (float) Transformer prediciton - the predcition of Tranformer Model\n",
        "        (float) Real - the value of Close in the last day\n",
        "  Returns:\n",
        "      (Array) Decision -array of values of [-1,0,1] \n",
        "  '''\n",
        "  # Fromula\n",
        "  percent=real*0.5/100\n",
        "\n",
        "  predictions=[reg_pred,arima_pred,lstm_pred,prophet_pred,trans_pred]\n",
        "  \n",
        "  decisions=[]\n",
        "  for i in predictions:\n",
        " \n",
        "    if i>real+percent:\n",
        "      action=1\n",
        "\n",
        "    elif i<real-percent:\n",
        "      action=-1\n",
        "\n",
        "    else:\n",
        "      action=0\n",
        "    \n",
        "    decisions.append(action)\n",
        "  \n",
        "  return decisions"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5LtzDp9RK_A"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def d3_scale(data, out_range=(0, 1)):\n",
        "  '''\n",
        "    Scale values from 0 to 1  \n",
        "    Args:\n",
        "        (float) data - The unscaled data \n",
        "        (tuple) data - The range of the new scaled data \n",
        "        \n",
        "  Returns:\n",
        "      (Array) array that has values from 0 into 1  '''\n",
        "  domain = [np.min(data, axis=0), np.max(data, axis=0)]\n",
        "\n",
        "  def interp(x):\n",
        "      return out_range[0] * (1.0 - x) + out_range[1] * x\n",
        "\n",
        "  def uninterp(x):\n",
        "      b = 0\n",
        "      if (domain[1] - domain[0]) != 0:\n",
        "          b = domain[1] - domain[0]\n",
        "      else:\n",
        "          b =  1.0 / domain[1]\n",
        "      return (x - domain[0]) / b\n",
        "\n",
        "  return interp(uninterp(data))\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UT81z4BkFTdE"
      },
      "source": [
        "\n",
        "def prophet (ticker):\n",
        "  \"\"\"\n",
        "  Forcasting using prophet ! by Getting the desired data from yahoo, then doing some data manipulation, then the comes the prophet's turn\n",
        "  Args:\n",
        "      (str) ticket - the ticker of desired dataset (company)\n",
        "  Returns:\n",
        "      (float) prophet_output - the model out-put (the prediction of the next day)\n",
        "  \"\"\"\n",
        "\n",
        "  # data_gathering\n",
        "  df = pdr.DataReader(ticker, data_source='yahoo', start='2015-01-01')\n",
        "\n",
        "  # data manipulation\n",
        "  holiday = pd.DataFrame([])\n",
        "  for date, name in sorted(holidays.UnitedStates(years=[2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021]).items()):\n",
        "      holiday = holiday.append(pd.DataFrame({'ds': date, 'holiday': \"US-Holidays\"}, index=[0]), ignore_index=True)\n",
        "  holiday['ds'] = pd.to_datetime(holiday['ds'], format='%Y-%m-%d', errors='ignore')\n",
        "\n",
        "  # data frame modification to be accepted by prophet\n",
        "  data = df['Close'].reset_index()\n",
        "  data.columns = ['ds', 'y']\n",
        "\n",
        "  # model building\n",
        "  m = Prophet(holidays=holiday,seasonality_mode='additive', changepoint_prior_scale = 0.1, seasonality_prior_scale=0.01)\n",
        "  m.fit(data)\n",
        "\n",
        "  # model predictions\n",
        "  future = m.make_future_dataframe(periods=1)\n",
        "  model_prediction = m.predict(future) \n",
        "  prophet_prediction = float(model_prediction[ 'yhat'][-1:])\n",
        "  return prophet_prediction\n",
        "\n",
        "\n",
        "def arima(ticker):\n",
        "  \"\"\"\n",
        "  Forcasting using ARIMA ! by Getting the desired data from yahoo, \n",
        "  then finding the best order of arima params then the comes the ARIMA's turn\n",
        "  Args:\n",
        "      (str) ticket - the ticker of desired dataset (company)\n",
        "  Returns:\n",
        "      (float) arima_output - the model out-put (the prediction of the next day)\n",
        "      (float) diff - the model output - today's price (the diff between tomorrow's prediction and today's real value)\n",
        "  \"\"\"\n",
        "    \n",
        "  # data gathering\n",
        "  df = pdr.DataReader(ticker, data_source='yahoo', start='2016-01-01')\n",
        "  df.index = pd.to_datetime(df.index, format=\"%Y/%m/%d\")\n",
        "  df = pd.Series(df['Close'])\n",
        "  last_day=df[-1]\n",
        "\n",
        "  # finding the best order\n",
        "  auto_order = pm.auto_arima(df, start_p=0, start_q=0, test='adf', max_p=3, max_q=3, m=1,d=None,seasonal=False   \n",
        "                    ,start_P=0,D=0, trace=True,error_action='ignore',suppress_warnings=True,stepwise=True)\n",
        "  best_order = auto_order.order\n",
        "\n",
        "  # model fitting\n",
        "  model = ARIMA(df, order=best_order)\n",
        "  model_fit = model.fit(disp=0)\n",
        "  arima_prediction ,se, conf = model_fit.forecast(1)\n",
        "  \n",
        "  diff = arima_prediction - last_day\n",
        "  \n",
        "  return arima_prediction , diff\n",
        "\n",
        "\n",
        "def lstm(data_set):\n",
        "  \"\"\"\n",
        "  Getting the desired data from yahoo, then doing some data manipulation such as data\n",
        "  reshaping\n",
        "  Args:\n",
        "      (str) data_set - the ticker of desired dataset (company)\n",
        "  Returns:\n",
        "      (float) diff_prediction - the model out-put (the prediction of the next day)\n",
        "      (float) real_prediction - the model output + today's price (real price of tomorrow)\n",
        "  \"\"\"\n",
        "\n",
        "  # data gathering\n",
        "  df = pdr.DataReader(data_set, data_source='yahoo', start=date.today() - timedelta(100))\n",
        "\n",
        "  # data manipulation\n",
        "\n",
        "  # creating a new df with Xt - Xt-1 values of the close prices (most recent 60 days)\n",
        "  close_df = df['2012-01-01':].reset_index()['Close'][-61:]\n",
        "  close_diff = close_df.diff().dropna()\n",
        "  data = np.array(close_diff).reshape(-1, 1)\n",
        "\n",
        "  # reshaping the data to 3D to be accepted by our LSTM model\n",
        "  model_input = np.reshape(data, (1, 60, 1))\n",
        "\n",
        "  # loading the model and predicting\n",
        "  loaded_model = load_model(\"lstm_f_60.hdf5\")\n",
        "  model_prediction = float(loaded_model.predict(model_input))\n",
        "  real_prediction = model_prediction + df['Close'][-1]\n",
        "  \n",
        "\n",
        "  return model_prediction, real_prediction\n",
        "\n",
        "\n",
        "def Regression(ticker):\n",
        "  \"\"\"\n",
        "  Forcasting using an ensambled model between SVR, Ridge and Linear regression! by Getting the desired data from yahoo, \n",
        "  then doing some data manipulation\n",
        "  Args:\n",
        "      (str) ticket - the ticker of desired dataset (company)\n",
        "  Returns:\n",
        "      (float) arima_output - the model out-put (the prediction of the next day)\n",
        "      (float) diff - the model output - today's price (the diff between tomorrow's prediction and today's real value)\n",
        "  \"\"\"\n",
        "  start_date = datetime.now() - timedelta(7)\n",
        "  start_date = datetime.strftime(start_date, '%Y-%m-%d')\n",
        "\n",
        "  df = pdr.DataReader(ticker, data_source='yahoo', start=start_date)  # read data\n",
        "  df.drop('Volume', axis='columns', inplace=True)\n",
        "\n",
        "  if df.index[-1]==datetime.now().strftime('%Y-%m-%d') :\n",
        "    df=df.iloc[-2:]\n",
        "  else :\n",
        "    df =df.iloc[-1:]\n",
        "  X = df[['High', 'Low', 'Open', 'Adj Close']]  # input columns\n",
        "  y = df[['Close']]  # output column\n",
        "  input = X\n",
        "  loaded_model = pickle.load(open('regression_model.pkl', 'rb'))\n",
        "  reg_prediction = loaded_model.predict(input)\n",
        "  reg_diff=reg_prediction-df.Close[-1]\n",
        "\n",
        "  return  reg_prediction,reg_diff\n",
        "\n",
        "def Transformer(ticker):\n",
        "  seq_len = 32\n",
        "\n",
        "  start_date = datetime.now() - timedelta(48)\n",
        "  start_date = datetime.strftime(start_date, '%Y-%m-%d')\n",
        "\n",
        "  df = pdr.DataReader(ticker, data_source='yahoo', start=start_date)\n",
        "\n",
        "  df.drop('Volume', axis=1, inplace=True)\n",
        "\n",
        "  # df[df.columns] = scaler.fit_transform(df)\n",
        "  df = df[['High', 'Low', 'Open', 'Adj Close', 'Close']]\n",
        "\n",
        "  '''Create training, validation and test split'''\n",
        "\n",
        "  test_data = df.values\n",
        "\n",
        "  # Test data\n",
        "  X_test, y_test = [], []\n",
        "  for i in range(seq_len, len(test_data)):\n",
        "      X_test.append(test_data[i - seq_len:i])\n",
        "      y_test.append(test_data[:, 4][i])\n",
        "  X_test, y_test = np.array(X_test), np.array(y_test)\n",
        "\n",
        "  custom_objects = {\"Time2Vector\": Time2Vector,\n",
        "                    \"MultiAttention\": MultiAttention,\n",
        "                    'TransformerEncoder': TransformerEncoder}\n",
        "  with keras.utils.custom_object_scope(custom_objects):\n",
        "      final_model = load_model('Transformer+TimeEmbedding.hdf5')\n",
        "\n",
        "  trans_prediction = float(final_model.predict(X_test)[-1])\n",
        "  trans_difference = trans_prediction - df.Close[-1]\n",
        "\n",
        "  return trans_prediction, trans_difference\n",
        "\n",
        "def real (ticker):\n",
        "  \n",
        "  start_date = datetime.now() - timedelta(10)\n",
        "  start_date = datetime.strftime(start_date, '%Y-%m-%d')\n",
        "\n",
        "  df = pdr.DataReader(ticker, data_source='yahoo', start=start_date)  # read data\n",
        "  df.drop('Volume', axis='columns', inplace=True)\n",
        "\n",
        "  if df.index[-1]==datetime.now().strftime('%Y-%m-%d') :\n",
        "    close=df.Close[-2]\n",
        "  \n",
        "  else :\n",
        "    close =df.Close[-1]\n",
        "  \n",
        "  return close\n",
        " \n",
        " "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O74wKY5AFVsa",
        "outputId": "e35f46ba-dea3-42c9-d807-81d0cb3746a4"
      },
      "source": [
        "app = FastAPI()\n",
        "\n",
        "\n",
        "@app.get('/')\n",
        "def index():\n",
        "    return {'message': 'This is your fav stock predictor!'}\n",
        "\n",
        "\n",
        "@app.post('/predict')\n",
        "async def predict_price(data: str):\n",
        "    if data == 'F':\n",
        "      prophet_prediction = float(prophet(data))\n",
        "      arima_prediction, diff = arima(data)\n",
        "      model_prediction, lstm_prediction = lstm(data)\n",
        "      reg_prediction,reg_diff = Regression(data)\n",
        "      trans_prediction, trans_difference = Transformer(data)\n",
        "      close=real(data)\n",
        "      \n",
        "      indicators=np.array(indicator(reg_prediction[0],arima_prediction[0],lstm_prediction,prophet_prediction,trans_prediction,close))\n",
        "      weights=np.array([0.3,0.3,0.3,0.05,0.05])\n",
        "      \n",
        "      \n",
        "      final_decision=indicators*weights\n",
        "      final_decision=final_decision.sum()\n",
        "      final_decision=final_decision.item(0)\n",
        "      decision_array=np.array([-1,final_decision,1],dtype=np.float)\n",
        "      decision_array=d3_scale(decision_array)\n",
        "      final_decision=round(decision_array[1],1)*10\n",
        "\n",
        "\n",
        "      \n",
        "\n",
        "      return {\n",
        "        'Decision': final_decision\n",
        "        \n",
        "            }\n",
        "\n",
        "    else:\n",
        "      return {\"the ticker not supported yet\"}\n",
        "\n",
        "    \n",
        "\n",
        "# App startup\n",
        "ngrok_tunnel = ngrok.connect(8090)\n",
        "print('Public URL:', ngrok_tunnel.public_url)\n",
        "nest_asyncio.apply()\n",
        "uvicorn.run(app, port=8090)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Public URL: http://3839cc4e16d2.ngrok.io\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:     Started server process [939]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://127.0.0.1:8090 (Press CTRL+C to quit)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:     154.181.127.172:0 - \"GET / HTTP/1.1\" 200 OK\n",
            "INFO:     154.181.127.172:0 - \"GET /favicon.ico HTTP/1.1\" 404 Not Found\n",
            "INFO:     154.181.127.172:0 - \"GET /docs HTTP/1.1\" 200 OK\n",
            "INFO:     154.181.127.172:0 - \"GET /openapi.json HTTP/1.1\" 200 OK\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Performing stepwise search to minimize aic\n",
            " ARIMA(0,1,0)(0,0,0)[0] intercept   : AIC=-490.809, Time=0.26 sec\n",
            " ARIMA(1,1,0)(0,0,0)[0] intercept   : AIC=-488.811, Time=0.09 sec\n",
            " ARIMA(0,1,1)(0,0,0)[0] intercept   : AIC=-488.811, Time=0.33 sec\n",
            " ARIMA(0,1,0)(0,0,0)[0]             : AIC=-492.791, Time=0.09 sec\n",
            " ARIMA(1,1,1)(0,0,0)[0] intercept   : AIC=-486.809, Time=0.35 sec\n",
            "\n",
            "Best model:  ARIMA(0,1,0)(0,0,0)[0]          \n",
            "Total fit time: 1.140 seconds\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tsa/arima_model.py:472: FutureWarning:\n",
            "\n",
            "\n",
            "statsmodels.tsa.arima_model.ARMA and statsmodels.tsa.arima_model.ARIMA have\n",
            "been deprecated in favor of statsmodels.tsa.arima.model.ARIMA (note the .\n",
            "between arima and model) and\n",
            "statsmodels.tsa.SARIMAX. These will be removed after the 0.12 release.\n",
            "\n",
            "statsmodels.tsa.arima.model.ARIMA makes use of the statespace framework and\n",
            "is both well tested and maintained.\n",
            "\n",
            "To silence this warning and continue using ARMA and ARIMA until they are\n",
            "removed, use:\n",
            "\n",
            "import warnings\n",
            "warnings.filterwarnings('ignore', 'statsmodels.tsa.arima_model.ARMA',\n",
            "                        FutureWarning)\n",
            "warnings.filterwarnings('ignore', 'statsmodels.tsa.arima_model.ARIMA',\n",
            "                        FutureWarning)\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tsa/base/tsa_model.py:583: ValueWarning:\n",
            "\n",
            "A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tsa/base/tsa_model.py:583: ValueWarning:\n",
            "\n",
            "A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:     154.181.127.172:0 - \"POST /predict?data=F HTTP/1.1\" 200 OK\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:pyngrok.process.ngrok:t=2021-06-28T21:55:45+0000 lvl=info msg=\"received stop request\" obj=app stopReq=\"{err:<nil> restart:false}\"\n",
            "INFO:     Shutting down\n",
            "INFO:uvicorn.error:Shutting down\n",
            "INFO:     Waiting for application shutdown.\n",
            "INFO:uvicorn.error:Waiting for application shutdown.\n",
            "INFO:     Application shutdown complete.\n",
            "INFO:uvicorn.error:Application shutdown complete.\n",
            "INFO:     Finished server process [939]\n",
            "INFO:uvicorn.error:Finished server process [939]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WKt2N9YmEYs"
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    }
  ]
}