# -*- coding: utf-8 -*-
"""Trans1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UItNy65f8qC9GYWn6VLGj-X2EgDHiUEX
"""

# Commented out IPython magic to ensure Python compatibility.
 from google.colab import drive 
drive.mount('/content/drive')
# %cd drive/MyDrive/Final2/
!ls

# Commented out IPython magic to ensure Python compatibility.



# %load_ext autoreload
# %reload_ext autoreload
# %autoreload 2

from utils.get_data import get_data
from sklearn.metrics import mean_absolute_error,mean_squared_error
import matplotlib.pyplot as plt

df, X_train, y_train, X_val, y_val, X_test, y_test,train_data_len,val_data_len,scaler = get_data()
print(df.head())
print(df.tail())

from utils.get_model import get_model
from utils.train import train_model

n = 256
model = get_model(seq_len=32,
                  d_k = n, d_v = n,
                  n_heads = 12, ff_dim = n,
                  encoder_stack_size = 1, 
                  loss='mse', 
                  output_activation='linear')

train_model(model, epoches=250, batch=32)

from utils.Time2Vector import Time2Vector
from utils.Attention import MultiAttention, SingleAttention
from utils.Encoder import TransformerEncoder
from tensorflow import keras
from keras.models import load_model
custom_objects = {"Time2Vector":Time2Vector,
                      "MultiAttention":MultiAttention,
                      'TransformerEncoder':TransformerEncoder}
with keras.utils.custom_object_scope(custom_objects):
      final_model=load_model('Transformer+TimeEmbedding.hdf5')